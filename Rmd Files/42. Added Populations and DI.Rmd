---
title: "42. Added Populations and DI"
author: "Daniel Zoleikhaeian"
date: "2023-06-28"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup

## Importing COGS2 data
```{r}
library(grid)
library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
df_COGS2 <- read.csv('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\3 Studies Dataset\\Dataset Merge\\bgc_merge_cDiag123_060723.csv')
df_COGS2 <- df_COGS2[df_COGS2$cStudy == 'COGS2', ]
nrow(df_COGS2)

head(df_COGS2)
# adding year column
df_COGS2$cEnrollmentYear <- as.numeric(substr(df_COGS2$cEnrollmentDateYear, 1,4))
head(df_COGS2)

unique(df_COGS2$cRace)

# re-encoding OT/UNK/MR into one group
df_COGS2$cRace2 <- df_COGS2$cRace
df_COGS2$cRace2[df_COGS2$cRace2 %in% c('OT', 'OT/UNK', 'MR', 'UNK')] <- 'OT/MR'
nrow(df_COGS2)

# removing San Diego observations
no_sd <- df_COGS2[df_COGS2$cLocationCity != 'San Diego', ]
```

## Helper function: Diversity Index
```{r}
mult_ent <- function(race_prop_vec) {
  
  tot <- 0
  
  for (i in 1:length(race_prop_vec)) {
    if (race_prop_vec[i] != 0) {
      tot <- tot + race_prop_vec[i] * log(1/race_prop_vec[i])
    }
  }
  return(tot)
}
```

### Helper function: Transforming by dictionary
```{r}
dict_transform <- function(keys, values, vec) {
  for (i in 1:length(keys)) {
    vec[vec == keys[i]] <- values[i]
  }
  return (vec)
}
```


## Importing ACS Data
## Importing and checking data
```{r}
df_acs <- read.csv('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\acs_cogs2_1014.csv')
unique(df_acs$CITY) # all cities except SD
head(df_acs)

# no missing data
sum(complete.cases(df_acs)) == nrow(df_acs)

```

## Encoding new race categories, binarizing hispan category
```{r}
df_acs$Race2 <- rep(0, nrow(df_acs))
df_acs$Hispan2 <- rep(0, nrow(df_acs))

sum(df_acs$HISPAN == 9) # everyone reported a hispanic status
df_acs$Hispan2 <- as.numeric(df_acs$HISPAN != 0) # 0 for not hispanic or latino, else 1

PI_raced <- c(680:699) # PI races

df_acs$Race2[df_acs$RACE == 1 ] <- 1 # White
df_acs$Race2[df_acs$RACE == 2 ] <- 2 # Black
df_acs$Race2[df_acs$RACE == 3 ] <- 3 # American Indian or Alaska Native
df_acs$Race2[df_acs$RACE %in% 4:6 & !(df_acs$RACED %in% PI_raced) ] <- 4 # Asian
df_acs$Race2[df_acs$RACE == 6 & df_acs$RACED %in% PI_raced ] <- 5 # Pacific Islander (or Native Hawaiian)
df_acs$Race2[df_acs$RACE %in% 7:9 ] <- 6 # Mixed/Other

# truncating the acs dataset
acs1865 <- df_acs[df_acs$AGE >= 18 & df_acs$AGE <= 65, ]
```

# Approximating Census Data

## Finding City Category Proportions using plyr::count
* NOTE: the Diversity Index is not 1-1
* As long as the category proportions are the same, then the resulting diversity index will be the same
* Need to check that the categories match too
* Method:
- Use category proportions instead of diversity index as the target metric
```{r}
# collection of target proportions
cityprops <- vector("list", 4)

cogs_codes <- unique(acs1865$CITY)
colnames(acs1865)
for (i in 1:length(cogs_codes)) {
  acs_counts <- plyr::count(acs1865[acs1865$CITY == cogs_codes[i], ], c('Race2', 'Hispan2', 'SEX'), wt_var = 'PERWT')
  acs_counts$prop <- acs_counts$freq / sum(acs_counts$freq)
  
  # converting the acs codes to match COGS2 variables
  acs_counts$Race2 <- dict_transform(c(1:6),c('CA', 'AA', 'AE','AS','NH','OT/MR'), acs_counts$Race2)
  acs_counts$Hispan2 <- dict_transform(c(0,1), c('No', 'Yes'), acs_counts$Hispan2)
  acs_counts$SEX <- dict_transform(c(1,2),c('M','F'), acs_counts$SEX)
  acs_counts <- acs_counts[order(acs_counts$Race2),]
  
  cityprops[[i]] <- acs_counts
}

city_names <- factor(cogs_codes)
unique(no_sd$cLocationCity)
levels(city_names) <- c('Los Angeles', 'New York', 'Philadelphia', 'Seattle')
names(cityprops) <- city_names

cityprops
```

ACS Codes notes:
- For sex: 1 = male, 2 = female
- For Race2: 
1 = White
2 = Black
3 = AI/AN
4 = Asian
5 = PI/NH
6 = Mixed/Other
- For Hispan: 1 = Hispanic or Latino, 0 = Not hispanic or latino

## Finding the target counts using the ACS data
```{r}
sizes <- plyr::count(no_sd, c('cLocationCity', 'cDiagnosis4'))
city_pops <- plyr::count(acs1865, c('CITY'), wt_var = 'PERWT')
city_names <- factor(city_pops$CITY)
levels(city_names) <- c('Los Angeles', 'New York', 'Philadelphia', 'Seattle')
city_pops$CITY <- city_names
# study_count / city_pop = scaling factor
# then scaling factor * prop from cityprop * count from cityprop

sizes$scale_factor <- rep(0,nrow(sizes))
for (i in 1:nrow(sizes)) {
  sizes$scale_factor[i] <- sizes$freq[i] / city_pops$freq[city_pops$CITY == sizes$cLocationCity[i]]
}

cs_targets <- sizes[sizes$cDiagnosis4 == 'CS',]
sz_targets <- sizes[sizes$cDiagnosis4 == 'SZSAFD',]
sizes2 <- plyr::count(no_sd, 'cLocationCity')
sizes2$scale_factor <- sizes2$freq / city_pops$freq
sizes2

for (i in 1:length(cityprops)) {
  if (names(cityprops)[i] == cs_targets$cLocationCity[i] & sz_targets$cLocationCity[i] == names(cityprops[i])) {
    
    in_cs <- cs_targets$scale_factor[i] * cityprops[[i]]$freq
    in_sz <- sz_targets$scale_factor[i] * cityprops[[i]]$freq
    in_ag <- sizes2$scale_factor[i] * cityprops[[i]]$freq
    
    # if the expected count is less than 1, set count to 0
    # else, round it 
    cityprops[[i]]$target_cs <- ifelse(in_cs < 1, 0, round(in_cs)) 
    cityprops[[i]]$target_sz <- ifelse(in_sz < 1, 0, round(in_cs))
    cityprops[[i]]$target_ag <- ifelse(in_ag < 1, 0, round(in_ag))
    }
}
cityprops
```

## Finding City Proportions for COGS2 - Aggregate
```{r}
cogsprops <- vector("list", 4)

cogs_cities <- unique(no_sd$cLocationCity)
for (i in 1:length(cogs_codes)) {
  cogs_counts <- plyr::count(no_sd[no_sd$cLocationCity == cogs_cities[i], ], c('cRace2', 'cHispanicorLatino', 'cGender'))
  cogs_counts$prop <- cogs_counts$freq / sum(cogs_counts$freq)
  cogsprops[[i]] <- cogs_counts
}

names(cogsprops) <- cogs_cities
cogsprops
```

## Finding the added population
```{r}
# la <- cogsprops$`Los Angeles`
# la_acs <- cityprops$`Los Angeles`
# la_ag <- la_acs[,c(1:5,8)]
# 
# # adding the missing rows
# 
# la$group_code <- paste(la[,1],la[,2],la[,3])
# la_ag$group_code <- paste(la_ag[,1], la_ag[,2],la_ag[,3])
# 
# miss_group <- setdiff(la_ag$group_code, la$group_code)
# setdiff(la$group_code, la_ag$group_code) # issues occur when this intersection is not 0
# # this means that the ACS sample was missing some combinations
# 
# miss_df <- data.frame(cRace2 = rep('',length(miss_group)), cHispanicorLatino = '',
#                       cGender=rep('',length(miss_group)), freq = rep(0,length(miss_group)), prop = rep(0,length(miss_group)),
#                       group_code = miss_group)
# 
# la <- rbind(la,miss_df)
# la <- la[order(la$group_code),]
# rownames(la) <- NULL
# la_ag <- la_ag[order(la_ag$group_code),]
# rownames(la_ag) <- NULL
# la_ag
# 
# la$add_pop <- la_ag$target_ag - la$freq
# la  
# 
# seattle_ag
# seattle


for (i in 1:length(cogsprops)) {
  cogs_sub <- cogsprops[[i]]
  acs_sub <- cityprops[[i]]
  acs_sub <- acs_sub[,c(1:5,8)]
  
  cogs_sub$group_code <- paste(cogs_sub[,1],cogs_sub[,2],cogs_sub[,3])
  acs_sub$group_code <- paste(acs_sub[,1], acs_sub[,2],acs_sub[,3])
  
  miss_group <- setdiff(acs_sub$group_code, cogs_sub$group_code)
  if(length(setdiff(cogs_sub$group_code, acs_sub$group_code)) != 0)   {
    print(names(cogsprops)[i])
    next
  } 
  # issues occur when this intersection is not 0
  # this means that the ACS sample was missing some combinations
  
  miss_df <- data.frame(cRace2 = rep('',length(miss_group)), cHispanicorLatino = '',
                        cGender=rep('',length(miss_group)), freq = rep(0,length(miss_group)), prop = rep(0,length(miss_group)),
                        group_code = miss_group)
  
  cogs_sub <- rbind(cogs_sub,miss_df)
  cogs_sub <- cogs_sub[order(cogs_sub$group_code),]
  rownames(cogs_sub) <- NULL
  acs_sub <- acs_sub[order(acs_sub$group_code),]
  rownames(acs_sub) <- NULL
  cityprops[[i]] <- acs_sub
  
  cogs_sub$add_pop <- acs_sub$target_ag - cogs_sub$freq
  cogsprops[[i]] <- cogs_sub
}

# Seattle is an issue
## Study sample has some categories that ACS sample does not
seattle_group_code <- paste(cogsprops$Seattle[,1],cogsprops$Seattle[,2],cogsprops$Seattle[,3])
seattle_acs_group_code <- paste(cityprops$Seattle[,1], cityprops$Seattle[,2],cityprops$Seattle[,3])
setdiff(seattle_group_code, seattle_acs_group_code)
# acs sample does not have Native Hawaiian + Latino + Male

# Additional issue: 
# Need to think of an algorithm for the "added population"
# Changing one count will affect the other count

cogsprops
```

# Finding Rarity of the Sample: Multivariate Hypergeometric Distribution

$$
P(y_1, ... y_n) = \frac {{m_1 \choose y_1} ...{m_n \choose y_n}}{{m \choose n}}
$$
Where:
* m_1, ...,m_n is the number in each category from the background population
* m is the total number of objects in the background population
* n is the number of objects in the sample
* y_1, ... y_n is the number of objects in each category in the sample

### Helper Function: multivariate hypergeometric distribution
```{r}
mv_hyper <- function(m, y, n) {
  prod <- 1
  for (i in 1:length(m)) {
    prod <- prod * choose(m[i],y[i])
  }
  res <- prod / choose(sum(m),n)
  return (res)
}
```

## Finding Rarity of Samples in COGS2
Approach:
* Use the counts from plyr::count(acs1865, categories, PERWT)
- These will be the "m_i" values
* Find the counts from plyr::count(cogs_city, categories)
- These will be the "y" values
* n = the city sample sizes
* m = the city population from PERWT sums
```{r}
cogsprops # do for everything except Seattle
sizes2

rarity <- rep(0,3)
for (i in 1:length(rarity)) {
  rarity[i] <- mv_hyper(cityprops[[i]]$freq, cogsprops[[i]]$freq, sizes2$freq[i])
}
rarity
mv_hyper(cityprops[[i]]$freq, cogsprops[[i]]$freq, sizes2$freq[i])

# Problem: Samples are too small
choose(sum(cityprops[[1]]$freq), sizes2$freq[1])

# Solution: try multinomial distribution
## Same thing as above but samples are independent

library(ggplot2)
cogsprops$`Los Angeles`

ggplot(data = cogsprops$`Los Angeles`, aes(x = cRace2, y = prop, fill = group_code)) + geom_bar(stat = 'identity', position = position_dodge())

cityprops$`Los Angeles`

ggplot(data = cityprops$`Los Angeles`, aes(x = Race2, y = prop, fill = group_code)) +  geom_bar(stat = 'identity', position = position_dodge())
```







