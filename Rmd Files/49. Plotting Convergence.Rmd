---
title: "45. Steps to Convergence"
author: "Daniel Zoleikhaeian"
date: "2023-07-08"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup

## Importing COGS2 data
```{r}
library(grid)
library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)

df_COGS2 <- read.csv('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\3 Studies Dataset\\Dataset Merge\\bgc_merge_cDiag123_060723.csv')
df_COGS2 <- df_COGS2[df_COGS2$cStudy == 'COGS2', ]
nrow(df_COGS2)

head(df_COGS2)
# adding year column
df_COGS2$cEnrollmentYear <- as.numeric(substr(df_COGS2$cEnrollmentDateYear, 1,4))
head(df_COGS2)

unique(df_COGS2$cRace)

# re-encoding OT/UNK/MR into one group
df_COGS2$cRace2 <- df_COGS2$cRace
df_COGS2$cRace2[df_COGS2$cRace2 %in% c('OT', 'OT/UNK', 'MR', 'UNK')] <- 'OT/MR'
nrow(df_COGS2)

# removing San Diego observations
no_sd <- df_COGS2[df_COGS2$cLocationCity != 'San Diego', ]
```

### Helper function: Transforming by dictionary
```{r}
dict_transform <- function(keys, values, vec) {
  for (i in 1:length(keys)) {
    vec[vec == keys[i]] <- values[i]
  }
  return (vec)
}
```

### Group code manipulations
```{r}
group_codes_df <- data.frame(Race2 = rep(c('AA', 'AE', 'AS','CA','NH','OT/MR'), rep(4,6)),
                             Hispan2 = rep(rep(c('No','Yes'), c(2,2)), 6),
                             Gender = rep(c('F','M'), 12),
                             group_code = 1:24)

group_code_gen <- function(df, handbook) {
  df$group_code <- rep(0,nrow(df))
  for (n in 1:nrow(df)) {
    for (i in 1:nrow(handbook)) {
      if (df[n,1] == handbook[i,1] &&
          df[n,2] == handbook[i,2] &&
          df[n,3] == handbook[i,3]) {
        df$group_code[n] <- handbook$group_code[i]
        break
      } else {
        next
      }
    }
  }
  return (df)
}

group_code_inverse <- function(df, handbook) {
  df <- cbind(handbook[handbook$group_code %in% df$group_code, 1:3], df)
  return(df)
}

quickdf <- function(l) {
  class(l) <- "data.frame"
  attr(l, "row.names") <- .set_row_names(length(l[[1]]))
  l
}
```


## Importing ACS Data
```{r}
df_acs <- read.csv('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\acs_cogs2_1014.csv')
unique(df_acs$CITY) # all cities except SD
head(df_acs)
```

## Encoding new race categories, binarizing hispan category
```{r}
df_acs$Race2 <- rep(0, nrow(df_acs))
df_acs$Hispan2 <- rep(0, nrow(df_acs))

sum(df_acs$HISPAN == 9) # everyone reported a hispanic status
df_acs$Hispan2 <- as.numeric(df_acs$HISPAN != 0) # 0 for not hispanic or latino, else 1

PI_raced <- c(680:699) # PI races

df_acs$Race2[df_acs$RACE == 1 ] <- 1 # White
df_acs$Race2[df_acs$RACE == 2 ] <- 2 # Black
df_acs$Race2[df_acs$RACE == 3 ] <- 3 # American Indian or Alaska Native
df_acs$Race2[df_acs$RACE %in% 4:6 & !(df_acs$RACED %in% PI_raced) ] <- 4 # Asian
df_acs$Race2[df_acs$RACE == 6 & df_acs$RACED %in% PI_raced ] <- 5 # Pacific Islander (or Native Hawaiian)
df_acs$Race2[df_acs$RACE %in% 7:9 ] <- 6 # Mixed/Other

# truncating the acs dataset
acs1865 <- df_acs[df_acs$AGE >= 18 & df_acs$AGE <= 65, ]
```

## Pooling the cities together, weighted by COGS counts for CS
```{r}

# finding cogs city counts
city_counts <- plyr::count(no_sd[no_sd$cDiagnosis4 == 'CS', ], 'cLocationCity')

colnames(acs1865)
city_counts_acs <- plyr::count(acs1865, 'CITY', wt_var = 'PERWT')
city_counts_acs
# city_counts$proportion <- city_counts$freq / sum(city_counts$freq) # used to reweight the PERWT
city_counts
city_counts$proportion <- city_counts$freq / city_counts_acs$freq
city_counts

```

## City proportions
```{r}
# collection of target proportions
cityprops <- vector("list", 4)

cogs_codes <- unique(acs1865$CITY)


# reweighting all the person weights by the frequencies found in COGS for CS
for (i in 1:length(cogs_codes)) {
  acs1865$PERWT_CS[acs1865$CITY == cogs_codes[i]] <- acs1865$PERWT[acs1865$CITY == cogs_codes[i]] * city_counts$proportion[i]
}

colnames(acs1865)
```


## PERWT Demonstration
```{r}
acs1865_sub <- acs1865[, c('CITY','Race2','Hispan2','SEX','PERWT','PERWT_CS')]

#subsetting by city code 3730 (Los Angeles)
acs1865_LA <- acs1865_sub[acs1865_sub$CITY == 3730,]
acs1865_NY <- acs1865_sub[acs1865_sub$CITY == 4610,]

# This dataframe shows how much of the city population the cogs sample captured
city_counts

# Showing that the proportion x the PERWT = PERWT_CS
all(city_counts$proportion[1] * acs1865_LA$PERWT == acs1865_LA$PERWT_CS)

# Showing that the original sample size is recovered
sum(acs1865_LA$PERWT_CS)
sum(acs1865_NY$PERWT_CS)
city_counts

df_PERWT <- data.frame(Race2 = acs1865_LA$Race2,
                       Hispan2 = acs1865_LA$Hispan2,
                       Gender = acs1865_LA$SEX,
                       og_PERWT = acs1865_LA$PERWT,
           rescaled_PERWT = acs1865_LA$PERWT_CS)
head(df_PERWT)
```


```{r}

pool_cs <- plyr::count(acs1865, c('Race2', 'Hispan2', 'SEX'), wt_var = 'PERWT_CS')
pool_cs$prop <- pool_cs$freq/sum(pool_cs$freq)
pool_cs$Race2 <- dict_transform(c(1:6),c('CA', 'AA', 'AE','AS','NH','OT/MR'), pool_cs$Race2)
pool_cs$Hispan2 <- dict_transform(c(0,1), c('No', 'Yes'), pool_cs$Hispan2)
pool_cs$SEX <- dict_transform(c(1,2),c('M','F'), pool_cs$SEX)
pool_cs <- pool_cs[order(pool_cs$Race2,pool_cs$Hispan2,pool_cs$SEX),]

pool_cs <- group_code_gen(pool_cs, group_codes_df)
pool_cs 

# these are the target proportions
```

## Pool generator function
```{r}
pool_gen <- function(Diag4, cogs_data, acs_data, grp_codes_df) {
  city_counts <- plyr::count(cogs_data[cogs_data$cDiagnosis4 == Diag4, ], 'cLocationCity')
  #city_counts$proportion <- city_counts$freq / sum(city_counts$freq) # used to reweight the PERWT
  
  city_counts_acs <- plyr::count(acs_data, 'CITY', wt_var = 'PERWT')
  
  # city_counts$proportion <- city_counts$freq / sum(city_counts$freq) # used to reweight the PERWT
  city_counts$proportion <- city_counts$freq / city_counts_acs$freq
  
  # collection of target proportions
  cityprops <- vector("list", 4)
  
  cogs_codes <- unique(acs_data$CITY)
  colnames(acs_data)
  
  # reweighting all the person weights by the frequencies found in COGS for CS
  for (i in 1:length(cogs_codes)) {
    acs_data$PERWT_Diag[acs_data$CITY == cogs_codes[i]] <- acs_data$PERWT[acs_data$CITY == cogs_codes[i]] * city_counts$proportion[i]
  }
  
  pool <- plyr::count(acs_data, c('Race2', 'Hispan2', 'SEX'), wt_var = 'PERWT_Diag')
  pool$prop <- pool$freq/sum(pool$freq)
  pool$Race2 <- dict_transform(c(1:6),c('CA', 'AA', 'AE','AS','NH','OT/MR'), pool$Race2)
  pool$Hispan2 <- dict_transform(c(0,1), c('No', 'Yes'), pool$Hispan2)
  pool$SEX <- dict_transform(c(1,2),c('M','F'), pool$SEX)
  pool <- pool[order(pool$Race2,pool$Hispan2,pool$SEX),]
  
  pool <- group_code_gen(pool, grp_codes_df)
  
    cogs_data_diag <- cogs_data[cogs_data$cDiagnosis4 == Diag4,]
  cogs_counts <- plyr::count(cogs_data_diag, c('cRace2', 'cHispanicorLatino', 'cGender'))
  cogs_counts$props <- cogs_counts$freq / sum(cogs_counts$freq)
  cogs_counts <- group_code_gen(cogs_counts, grp_codes_df)
  cogs_counts

  # These are the unicorns - ignore these 
  pool[pool$group_code %in% setdiff(pool$group_code, cogs_counts$group_code),]
  # Asian Hispanics
  # American indians/Alaska natives
  # Native Hawaiian/ Pacific Islander Hispanics
  
  pool <- pool[pool$group_code %in% intersect(pool$group_code, cogs_counts$group_code),]
  
  
  return (pool) 
}
```

# Beginning the first run

## Setting the target proportions
```{r}
no_sd_cs <- no_sd[no_sd$cDiagnosis4 == 'CS',]
cogs_counts <- plyr::count(no_sd_cs, c('cRace2', 'cHispanicorLatino', 'cGender'))
cogs_counts$props <- cogs_counts$freq / sum(cogs_counts$freq)
cogs_counts <- group_code_gen(cogs_counts, group_codes_df)
cogs_counts

head(acs1865)
# These are the unicorns - ignore these 
pool_cs[pool_cs$group_code %in% setdiff(pool_cs$group_code, cogs_counts$group_code),]
# Asian Hispanics
# American indians/Alaska natives
# Native Hawaiian/ Pacific Islander Hispanics

pool_cs <- pool_cs[pool_cs$group_code %in% intersect(pool_cs$group_code, cogs_counts$group_code),]

pool_cs # these are the target proportions now
nrow(pool_cs)

pool_cs2 <- pool_gen('CS',no_sd,acs1865,group_codes_df)
identical(pool_cs2, pool_cs) # the pool generator function works
```

## Beginning the sampler
```{r}

sampling_algorithm_passes <- function(cogs_og, pool_df, scale_factor, thresh, n_iter, do_print = FALSE, suppress_df = TRUE, track_rej = FALSE, exp_runs) {
  
  # make an empty matrix to store the results of each pass of the algorithm
  # put the proportions after each pass into the columns 
  tracker <- matrix(-99, nrow = length(cogs_og$group_code), ncol = exp_runs)
  #rownames(tracker) <- cogs_og$group_code
  
  lnew_data <- list(freq = cogs_og$freq, group_code = cogs_og$group_code,
                 props = cogs_og$props)
  

  n_steps <- 0
  size_arg <- sum(cogs_og$freq) * scale_factor
  
  # start loop here
  
  if (track_rej) {
     number_rejected <- data.frame(group_code = cogs_og$group_code,
                                  n = rep(0, nrow(cogs_og)))        
  }
   
  
  for (N in 1:n_iter) {
    
    # check stop condition: if all the new proportions are within 0.05 of the acs proportions, then stop
    if (all(lnew_data$props >= (pool_df$prop - thresh)&
    lnew_data$props <= pool_df$prop + thresh)) {
   
      if (do_print) {cat('Number of steps:', n_steps, '\n')}
      break
    }
  
    
    
    # Methodology: sample from the group_codes based on the proportion found in the original cogs_counts
    sam <- sample(x = cogs_og$group_code, size = size_arg, prob = cogs_og$props, replace = TRUE)
    sam_counts <- plyr::count(sam)
    
    # for each group code in cogs_counts
    for (i in 1:nrow(cogs_og)) {
      
      # first check if the group was in the sample
      if (any(cogs_og$group[i] %in% sam_counts$x)) {
        # check whether the category is currently overrepresented
        # if it is, then don't touch it
        if (lnew_data$props[i] > pool_df$prop[i]) {
          # update the number rejected
          # but don't update the counts
          if (track_rej) {
            number_rejected$n[number_rejected$group_code == cogs_og$group_code[i]] <- number_rejected$n[number_rejected$group_code == cogs_og$group_code[i]] + sam_counts$freq[sam_counts$x == cogs_og$group_code[i]]
          }
          
          
        } else {
          # the add the people to the sample
          lnew_data$freq[i] <- lnew_data$freq[i] + sam_counts$freq[sam_counts$x == lnew_data$group_code[i]] 
        }
      }
    }
    
    # update the proportions
    lnew_data$props <- lnew_data$freq / sum(lnew_data$freq)
    
    
    # update the number of iterations
    n_steps <- n_steps + 1
    
    # add the result to the matrix
    tracker[,n_steps] <- lnew_data$props
  }
  
  if (N == n_iter && do_print) {
    cat('Did not converge in', n_steps, 'steps.\n')
  }
  
  if (suppress_df) {
    return(n_steps) 
  } else {
    df_out <- as.data.frame(cbind(group_code = cogs_og$group_code, V2 = cogs_og$props,tracker[,1:n_steps]))

    #colnames(df_out)[1] <- 'group_code'
    return (list(df_out, n_steps))
  }
}

s1 <- Sys.time()
output <- sampling_algorithm_passes(cogs_og = cogs_counts, pool_df = pool_cs, scale_factor = 0.5, thresh = 0.025, n_iter = 1000, do_print = FALSE, suppress_df = FALSE, exp_runs = 100)
s2 <- Sys.time()

df <- output[[1]]
colnames(df)[1] <- 'group_code'
df
View(output[[1]])
View(output[[2]])

s2 - s1
```

## Plotting results
```{r}

output <- sampling_algorithm_passes(cogs_og = cogs_counts, pool_df = pool_cs, scale_factor = 0.5, thresh = 0.025, n_iter = 1000, do_print = FALSE, suppress_df = FALSE, exp_runs = 100)

plot(NA, xlim = c(0, output[[2]]), ylim = c(0,0.4), main = 'Proportion Shifts over Resamples', xlab = 'Step Number', ylab = 'Proportion')

grid()

title("")

mtext('0.5 scale, 0.025 threshold',side=3)

my_cols <- hcl.colors(17, palette = 'Dark 3')


for (i in 1:nrow(output[[1]])) {
  lines(0:output[[2]], output[[1]][i, 2:ncol(output[[1]])], 
        col = my_cols[i],
        lwd = 1.5)
  
}


legend('top',
       legend = output[[1]][,1],
       title = 'Group Code',
       col = my_cols,
       lwd = 3,
       lty = 1, 
       ncol = 6,
       cex = 0.65)
```

