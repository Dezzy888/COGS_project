---
title: "55. Full COGS2 CS Convergence"
author: "Daniel Zoleikhaeian"
date: "2023-08-15"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Setup

### Importing COGS2 data
```{r}
library(grid)
library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(kableExtra)
library(tableHTML)

df_COGS2 <- read.csv('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\3 Studies Dataset\\Dataset Merge\\bgc_merge_cDiag123_060723.csv')
df_COGS2 <- df_COGS2[df_COGS2$cStudy == 'COGS2', ]
nrow(df_COGS2)

head(df_COGS2)
# adding year column
df_COGS2$cEnrollmentYear <- as.numeric(substr(df_COGS2$cEnrollmentDateYear, 1,4))
head(df_COGS2)

unique(df_COGS2$cRace)

# re-encoding OT/UNK/MR into one group
df_COGS2$cRace2 <- df_COGS2$cRace
df_COGS2$cRace2[df_COGS2$cRace2 %in% c('OT', 'OT/UNK', 'MR', 'UNK')] <- 'OT/MR'
nrow(df_COGS2)
```

### Helper function: Transforming by dictionary
```{r}
dict_transform <- function(keys, values, vec) {
  for (i in 1:length(keys)) {
    vec[vec == keys[i]] <- values[i]
  }
  return (vec)
}
```

### Group code manipulations
```{r}
group_codes_df <- data.frame(Race2 = rep(c('AA', 'AE', 'AS','CA','NH','OT/MR'), rep(4,6)),
                             Hispan2 = rep(rep(c('No','Yes'), c(2,2)), 6),
                             Gender = rep(c('F','M'), 12),
                             group_code = 1:24)

group_code_gen <- function(df, handbook) {
  df$group_code <- rep(0,nrow(df))
  for (n in 1:nrow(df)) {
    for (i in 1:nrow(handbook)) {
      if (df[n,1] == handbook[i,1] &&
          df[n,2] == handbook[i,2] &&
          df[n,3] == handbook[i,3]) {
        df$group_code[n] <- handbook$group_code[i]
        break
      } else {
        next
      }
    }
  }
  return (df)
}

group_code_inverse <- function(df, handbook) {
  df <- cbind(handbook[handbook$group_code %in% df$group_code, 1:3], df)
  return(df)
}
```


### COGS counts for diagnosis within a city
```{r}
# dependency: group codes block must be run already
cogs_city_ct_gen <- function(cogs_df, city_name, diagnosis4) {
  df_out <- plyr::count(cogs_df[cogs_df$cLocationCity == city_name & cogs_df$cDiagnosis4 == diagnosis4, ], vars = c('cRace2', 'cHispanicorLatino', 'cGender'))
  
  df_out$props <- df_out$freq / sum(df_out$freq)
  df_out <- group_code_gen(df_out, group_codes_df)
  return(df_out)
}
```

### Pool generator function
```{r}
pool_gen_city <- function(Diag4, cogs_data, city, city_code, acs_data, grp_codes_df) {
  
  cogs_sub <- cogs_data[cogs_data$cLocationCity == city & cogs_data$cDiagnosis4 == Diag4, ]
  cogs_counts <- plyr::count(cogs_sub, vars = c('cRace2', 'cHispanicorLatino', 'cGender'))
  cogs_counts <- group_code_gen(cogs_counts, grp_codes_df)
  
  acs_cts <- plyr::count(acs_data[acs_data$CITY == city_code,], vars = c('Race2', 'Hispan2','SEX'), wt = 'PERWT')
acs_cts$prop <- acs_cts$freq / sum(acs_cts$freq)



  acs_cts$Race2 <- dict_transform(c(1:6),c('CA', 'AA', 'AE','AS','NH','OT/MR'), acs_cts$Race2)
  acs_cts$Hispan2 <- dict_transform(c(0,1), c('No', 'Yes'), acs_cts$Hispan2)
  acs_cts$SEX <- dict_transform(c(1,2),c('M','F'), acs_cts$SEX)
  acs_cts <- acs_cts[order(acs_cts$Race2,acs_cts$Hispan2,acs_cts$SEX),]
  
  acs_cts <- group_code_gen(acs_cts, grp_codes_df)
  
  # keep only the categories that are observed in COGS
  pool <- acs_cts[acs_cts$group_code %in% intersect(acs_cts$group_code, cogs_counts$group_code),]
  
  # but add the stuff that COGS found but ACS did not
  # adding the missing group codes from pool_df
  # these are the people that COGS found but ACS did not
  miss_codes <- setdiff(cogs_counts$group_code, acs_cts$group_code)
  miss_df <- data.frame(group_code = miss_codes,
                        freq = rep(0,length(miss_codes)),
                        prop = rep(0,length(miss_codes)))
  miss_df <- group_code_inverse(miss_df, grp_codes_df)
  colnames(miss_df) <- c('Race2', 'Hispan2', 'SEX', 'group_code', 'freq', 'prop')

  pool <- rbind(pool, miss_df)
  pool <- pool[order(pool$Race2,pool$Hispan2,pool$SEX),]

  
  return (pool) 
}
```


### Sampling Algorithm
```{r}
sampling_algorithm <- function(cogs_og, pool_df, scale_factor, thresh, n_iter, do_print = FALSE, suppress_df = TRUE) {
  # making a copy of the original cogs data
  # this copy will be updated in each pass
  cogs_counts_updated <- cogs_og[, c('group_code', 'freq', 'props')]
  cogs_counts_updated$freq_og <- cogs_og$freq
  cogs_counts_updated$props_og <- cogs_og$props
  cogs_counts_updated$props_target <- pool_df$prop
  cogs_counts_updated <- cogs_counts_updated[, c('group_code', 'freq', 'freq_og','props_og','props_target','props')]

  n_steps <- 0
  size_arg <- sum(cogs_og$freq) * scale_factor
  
  # start loop here
  
  
  number_rejected <- data.frame(group_code = cogs_og$group_code,
                                  n = rep(0, nrow(cogs_og)))          
  
  for (N in 1:n_iter) {
    
    # check stop condition: if all the new proportions are within 0.05 of the acs proportions, then stop
    if (all(cogs_counts_updated$props >= (pool_df$prop - thresh)&
    cogs_counts_updated$props <= pool_df$prop + thresh)) {
    # if (all(((cogs_counts_updated$props - pool_df$prop) / pool_df$prop) < thresh)) {
      if (do_print) {cat('Number of steps:', n_steps, '\n')}
      break
    }
  
    
    
    # Methodology: sample from the group_codes based on the proportion found in the original cogs_counts
    
    sam <- sample(x = cogs_og$group_code, size = size_arg, prob = cogs_og$props, replace = TRUE)
    sam_counts <- plyr::count(sam)
    
    # verifying that all the group codes are in the right order
    # all(cogs_og$group_code == pool_df$group_code)
    
    # number_rejected <- data.frame(group_code = cogs_og$group_code,
    #                               n = rep(0, nrow(cogs_og)))
    # for each group code in cogs_counts
    for (i in 1:nrow(cogs_counts_updated)) {
      
      # first check if the group was in the sample
      if (any(cogs_counts_updated$group[i] %in% sam_counts$x)) {
        # check whether the category is currently overrepresented
        # if it is, then don't touch it
        if (cogs_counts_updated$props[i] > pool_df$prop[i]) {
          # update the number rejected
          # but don't update the counts
        # if (((cogs_counts_updated$props[i] - pool_df$prop[i]) / pool_df$prop[i]) >= thresh) {
          number_rejected$n[number_rejected$group_code == cogs_counts_updated$group_code[i]] <- number_rejected$n[number_rejected$group_code == cogs_counts_updated$group_code[i]] + sam_counts$freq[sam_counts$x == cogs_counts_updated$group_code[i]]
          
        } else {
          # the add the people to the sample
          cogs_counts_updated$freq[i] <- cogs_counts_updated$freq[i] + sam_counts$freq[sam_counts$x == cogs_counts_updated$group_code[i]] 
        }
      }
    }
    
    # update the proportions
    cogs_counts_updated$props <- cogs_counts_updated$freq / sum(cogs_counts_updated$freq)
    
    # update the number of iterations
    n_steps <- n_steps + 1
  }
  
  if (N == n_iter && do_print) {
    cat('Did not converge in', n_steps, 'steps.\n')
  }
  
  if (suppress_df) {
    return(n_steps) 
  } else {
    return (list(cogs_counts_updated, number_rejected, n_steps))
  }
}

```


### Sampling Algorithm Driver
```{r}
sim_runner <- function(nsim, th_in, sf_in, cogs_in, pool_in) {
  steps_storage <- rep(0, nsim)
  start_time <- Sys.time()
  for (i in 1:nsim) {
    steps_storage[i] <- sampling_algorithm(cogs_og = cogs_in, pool_df = pool_in, scale_factor = sf_in, thresh = th_in, n_iter = 1000, suppress_df = TRUE)
  }
  return(steps_storage)
}
```

### Histogram and Percentile Generator
```{r}
# theme for gridtable
myt <- ttheme_default(
                 base_size = 10,
         # Use hjust and x to left justify the text
         # Alternate the row fill colours
                 core = list(fg_params=list(hjust = 1, x=1),
                             bg_params=list(fill=c('lightblue', "white"))),

         # Change column header to white text and red background
                 colhead = list(fg_params=list(col="black"),
                                bg_params=list(fill="lightgray"))
 )


hist_perc <- function(steps_storage, freq_arg = TRUE, city_name, diagnosis, scale_factor, threshold, html_yes = FALSE) {
  
  rng <- range(steps_storage)
  hist(steps_storage, freq = freq_arg, main = paste(city_name, diagnosis, ': Number of Resamples\nuntil Convergence', sep = ' '), breaks = rng[1]:rng[2], xlab = 'Number of Resamples')
  title(sub = paste('Scale factor:', scale_factor, 'Threshold:', threshold), font.sub = 3, col.sub = 'darkgray')
  grid()
  steps_storage <- sort(steps_storage)
  perc_res <- quantile(steps_storage, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))
  
  sum_stats <- data.frame(Percentile = names(perc_res),
                          Value = unname(perc_res))
  
  if(html_yes) {
     tbl <- kbl(sum_stats, caption = paste(city_name, diagnosis, ": Number of Resamples until Convergence for Control Subjects"), table.attr = "style='width:50%;'" ) %>%
  kable_styling(bootstrap_options = "striped", full_width = T, position = "center") 
  } else {
    grid.newpage()
    grid.draw(tableGrob(format(sum_stats), theme=myt, rows=NULL))
  }
}
```


### Proportion tester
```{r}
prop_tester <- function(cogs_counts, pool, nom_alpha) {
  # double checking if all the group codes match
  if(!all(pool$group_code == cogs_counts$group_code) || nrow(pool) != nrow(cogs_counts)) {
    stop('Re-check group codes')
  }
  
  df_comparison <- cbind(cogs_counts, pool$prop)
  df_comparison$group_code <- NULL
  df_comparison$sam_over <- ifelse(cogs_counts$props > pool$prop, 'Over','-')
  df_comparison$sam_under <- ifelse(cogs_counts$props < pool$prop, 'Under','-')
  
  sig_res_p_vals <- rep(0, nrow(df_comparison))
  for (i in 1:nrow(df_comparison)) {
    test_obj <- binom.test(df_comparison$freq[i], n = sum(cogs_counts$freq), p = df_comparison$`pool$prop`[i], alternative = 'two.sided')
    sig_res_p_vals[i] <- test_obj$p.value
  }
  
  sig_res_p_vals
  
  holm_corr <- p.adjust(sig_res_p_vals, "holm")
  holm_corr
  
  sig_desig_cs <- ifelse(holm_corr < nom_alpha, '**', '-')
  sig_desig_cs
  
  df_comparison$significance <- sig_desig_cs
  df_comparison$holm_pval <- holm_corr
  return (df_comparison)
}

```

### Importing ACS Data
```{r}
df_acs <- read.csv('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\acs_1014_complete.csv')
```



## Not pooling the cities together

### Example for Los Angeles

#### Running Simulations
```{r}
df_cs <- df_COGS2[df_COGS2$cDiagnosis4 == 'CS',]
df_LA <- df_cs[df_cs$cLocationCity == 'Los Angeles',]
colnames(df_LA)

# getting the proportions
df_LA_counts <- plyr::count(df_LA, vars = c('cRace2', 'cHispanicorLatino', 'cGender'))
df_LA_counts$props <- df_LA_counts$freq / sum(df_LA_counts$freq)

head(df_LA_counts)

# testing cogs_city_ct_gen
identical(df_LA_counts, cogs_city_ct_gen(df_COGS2, 'Los Angeles', 'CS'))

unique(df_acs$CITY)

acs_la <- df_acs[df_acs$CITY == 3730, ]
colnames(df_acs)

acs_la_cts <- plyr::count(acs_la, vars = c('Race2', 'Hispan2','SEX'), wt = 'PERWT')
acs_la_cts$prop <- acs_la_cts$freq / sum(acs_la_cts$freq)

df_LA_counts <- group_code_gen(df_LA_counts, group_codes_df)
head(df_LA_counts)

acs_la_cts$Race2 <- dict_transform(c(1:6),c('CA', 'AA', 'AE','AS','NH','OT/MR'), acs_la_cts$Race2)
acs_la_cts$Hispan2 <- dict_transform(c(0,1), c('No', 'Yes'), acs_la_cts$Hispan2)
acs_la_cts$SEX <- dict_transform(c(1,2),c('M','F'), acs_la_cts$SEX)
acs_la_cts <- acs_la_cts[order(acs_la_cts$Race2,acs_la_cts$Hispan2,acs_la_cts$SEX),]

acs_la_cts <- group_code_gen(acs_la_cts, group_codes_df)
acs_la_cts <- acs_la_cts[acs_la_cts$group_code %in% intersect(acs_la_cts$group_code, df_LA_counts$group_code),]

acs_la_cts
pool_test <- pool_gen_city('CS', df_COGS2, 'Los Angeles', 3730, df_acs, group_codes_df)

# use the pool function to make it next time
identical(acs_la_cts, pool_test)

## running the simulation
n_sim <- 1000
th <- 0.025
sf <- 0.5

steps_storage_cs_la <- rep(0, n_sim)
start_time <- Sys.time()
for (i in 1:n_sim) {
  steps_storage_cs_la[i] <- sampling_algorithm(cogs_og = df_LA_counts, pool_df = pool_test, scale_factor = sf, thresh = th, n_iter = 1000, suppress_df = TRUE)
}
end_time <- Sys.time()

end_time - start_time

# showing results
rng <- range(steps_storage_cs_la)
hist(steps_storage_cs_la, freq = TRUE, main = 'LA CS: Number of Resamples\nuntil Convergence', breaks = rng[1]:rng[2], xlab = 'Number of Resamples')
title(sub = paste('Scale factor:', sf, 'Threshold:', th), font.sub = 3, col.sub = 'darkgray')
grid()
steps_storage_cs_la <- sort(steps_storage_cs_la)
conf_int <- c(steps_storage_cs_la[0.025*n_sim], steps_storage_cs_la[0.975*n_sim])
med_step <- median(steps_storage_cs_la)

perc_names <- c("2.5th",
                "1st Quartile",
                "Median",
                "3rd Quartile",
                "97.5th"
                )
perc_res <- quantile(steps_storage_cs_la, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))

sum_stats <- data.frame(Percentile = names(perc_res),
                        Value = unname(perc_res))
sum_stats


tbl <- kbl(sum_stats, format = 'html',caption = "LA: Number of Resamples until Convergence for Control Subjects", table.attr = "style='width:50%;'", booktabs = T) %>%
kable_styling(bootstrap_options = "striped", full_width = T, position = "center") %>% save_kable(file = 'Tester.pdf')
tbl


# verifying the algorithm worked
output <- sampling_algorithm(cogs_og = df_LA_counts, pool_df = pool_test, scale_factor = sf, thresh = th, n_iter = 1000, suppress_df = FALSE)
output[[1]]

# checking the hist_perc function
hist_perc(steps_storage_cs_la, city_name = 'LA', diagnosis = 'CS', scale_factor = 0.5, threshold = 0.025)

```

#### Checking the proportions
```{r}
# double checking if all the group codes match
all(pool_test$group_code == df_LA_counts$group_code)

df_comparison <- cbind(df_LA_counts, pool_test$prop)
df_comparison$group_code <- NULL
df_comparison$sam_over <- ifelse(df_LA_counts$props > pool_test$prop, 'Over','-')
df_comparison$sam_under <- ifelse(df_LA_counts$props < pool_test$prop, 'Under','-')

sig_res_p_vals <- rep(0, nrow(df_comparison))
for (i in 1:nrow(df_comparison)) {
  test_obj <- binom.test(df_comparison$freq[i], n = sum(df_LA_counts$freq), p = df_comparison$`pool_test$prop`[i], alternative = 'two.sided')
  sig_res_p_vals[i] <- test_obj$p.value
}

sig_res_p_vals

holm_corr <- p.adjust(sig_res_p_vals, "holm")
holm_corr

sig_desig_cs <- ifelse(holm_corr < 0.05, '**', '-')
sig_desig_cs

df_comparison$significance <- sig_desig_cs
df_comparison$holm_pval <- holm_corr
View(df_comparison)

# checking if prop tester function works
colnames(df_comparison)[6] <- 'pool$prop'
identical(df_comparison, prop_tester(df_LA_counts, pool_test, nom_alpha = 0.05)) # and it does
```

## Testing all COGS Cities

Functions for use:
- cogs_city_gen()
- pool_gen_city()
- sim_runner()
- hist_perc()
- prop_tester()

Pipeline:
1) Generate the proportions for the COGS data for a specific diagnosis and city
2) Generate the ACS proportions in that same city
3) Run the sampling algorithm
4) Create histogram of results
5) Test the initial proportions

```{r}
# matching the cities by position
cogs_cities <- sort(unique(df_COGS2$cLocationCity))
acs_cities <- sort(unique(df_acs$CITY))
prop_test_collection <- vector(mode = 'list', 5)
names(prop_test_collection) <- cogs_cities
plot_collection <- vector(mode = 'list', 5)
table_collection <- vector(mode = 'list', 5)

pdf(file = "C:/Users/danie/Documents/Joshi Lab Materials/3 Studies Dataset/Dataset Merge/Rmd Files/55.full_cogs_convergence_th03.pdf", paper = 'USr', width = 12)
for (i in 1:length(cogs_cities)) {
  cogs_city_data <- cogs_city_ct_gen(df_COGS2, city_name = cogs_cities[i], diagnosis4 = 'CS')
  acs_city_data <- pool_gen_city('CS', df_COGS2, cogs_cities[i], acs_cities[i], df_acs, group_codes_df)
  steps_repo <- sim_runner(1000, 0.025, 0.3, cogs_city_data, acs_city_data)
  hist_perc(steps_repo, TRUE, cogs_cities[i], 'CS', 0.3, 0.025)
  test_res <- prop_tester(cogs_city_data, acs_city_data, 0.05)
  prop_test_collection[[i]] <- test_res
  grid.newpage()
  grid.draw(tableGrob(format(test_res), theme=myt, rows=NULL))
}
dev.off()
```

## Same tests but for SZSAFD

```{r}
pdf(file = "C:/Users/danie/Documents/Joshi Lab Materials/3 Studies Dataset/Dataset Merge/Rmd Files/56.szsafd_full_cogs_convergence_th03.pdf", paper = 'USr', width = 12)
for (i in 1:length(cogs_cities)) {
  cogs_city_data <- cogs_city_ct_gen(df_COGS2, city_name = cogs_cities[i], diagnosis4 = 'SZSAFD')
  acs_city_data <- pool_gen_city('SZSAFD', df_COGS2, cogs_cities[i], acs_cities[i], df_acs, group_codes_df)
  steps_repo <- sim_runner(1000, 0.025, 0.3, cogs_city_data, acs_city_data)
  hist_perc(steps_repo, TRUE, cogs_cities[i], 'SZSAFD', 0.3, 0.025)
  test_res <- prop_tester(cogs_city_data, acs_city_data, 0.05)
  prop_test_collection[[i]] <- test_res
  grid.newpage()
  grid.draw(tableGrob(format(test_res), theme=myt, rows=NULL))
}
dev.off()
```



