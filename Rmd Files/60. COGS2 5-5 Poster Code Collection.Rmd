---
title: "60. COGS2 5-5 Poster Code Collection"
author: "Daniel Zoleikhaeian"
date: "2023-09-30"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup
* Importing Data
* Helper functions
* Group code manipulations

## Importing COGS2 data
```{r}
library(grid)
library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(Hmisc)
library(kableExtra)
library(tableHTML)


df_COGS2 <- read.csv('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\3 Studies Dataset\\Dataset Merge\\bgc_merge_cDiag123_060723.csv')
df_COGS2 <- df_COGS2[df_COGS2$cStudy == 'COGS2', ]
nrow(df_COGS2)

head(df_COGS2)
# adding year column
df_COGS2$cEnrollmentYear <- as.numeric(substr(df_COGS2$cEnrollmentDateYear, 1,4))
head(df_COGS2)

unique(df_COGS2$cRace)

# re-encoding OT/UNK/MR into one group
df_COGS2$cRace2 <- df_COGS2$cRace
df_COGS2$cRace2[df_COGS2$cRace2 %in% c('OT', 'OT/UNK', 'MR', 'UNK')] <- 'OT/MR'
nrow(df_COGS2)
```

## Importing ACS data
```{r}
df_acs <- read.csv('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\acs_1014_complete.csv')
```

## Helper function: Transforming by dictionary
```{r}
dict_transform <- function(keys, values, vec) {
  for (i in 1:length(keys)) {
    vec[vec == keys[i]] <- values[i]
  }
  return (vec)
}
```

## Group code manipulations
```{r}
group_codes_df <- data.frame(Race2 = rep(c('AA', 'AE', 'AS','CA','NH','OT/MR'), rep(4,6)),
                             Hispan2 = rep(rep(c('No','Yes'), c(2,2)), 6),
                             Gender = rep(c('F','M'), 12),
                             group_code = 1:24)

group_code_gen <- function(df, handbook) {
  df$group_code <- rep(0,nrow(df))
  for (n in 1:nrow(df)) {
    for (i in 1:nrow(handbook)) {
      if (df[n,1] == handbook[i,1] &&
          df[n,2] == handbook[i,2] &&
          df[n,3] == handbook[i,3]) {
        df$group_code[n] <- handbook$group_code[i]
        break
      } else {
        next
      }
    }
  }
  return (df)
}

group_code_inverse <- function(df, handbook) {
  df <- cbind(handbook[handbook$group_code %in% df$group_code, 1:3], df)
  return(df)
}
```

# Simulation-relevant functions

## Pool generator function
* Combines all the ACS data into one "pooled megacity"
* This would be as if all the sites in COGS2 were combined into one megacity
- Weighted in accordance to how many people from each city were found in COGS2
```{r}
pool_gen <- function(Diag4, cogs_data, acs_data, grp_codes_df) {
  city_counts <- plyr::count(cogs_data[cogs_data$cDiagnosis4 == Diag4, ], 'cLocationCity')
  #city_counts$proportion <- city_counts$freq / sum(city_counts$freq) # used to reweight the PERWT
  
  city_counts_acs <- plyr::count(acs_data, 'CITY', wt_var = 'PERWT')
  
  # city_counts$proportion <- city_counts$freq / sum(city_counts$freq) # used to reweight the PERWT
  city_counts$proportion <- city_counts$freq / city_counts_acs$freq
  
  # collection of target proportions
  cityprops <- vector("list", 4)
  
  cogs_codes <- unique(acs_data$CITY)
  colnames(acs_data)
  
  # reweighting all the person weights by the frequencies found in COGS for CS
  for (i in 1:length(cogs_codes)) {
    acs_data$PERWT_Diag[acs_data$CITY == cogs_codes[i]] <- acs_data$PERWT[acs_data$CITY == cogs_codes[i]] * city_counts$proportion[i]
  }
  
  pool <- plyr::count(acs_data, c('Race2', 'Hispan2', 'SEX'), wt_var = 'PERWT_Diag')
  pool$prop <- pool$freq/sum(pool$freq)
  pool$Race2 <- dict_transform(c(1:6),c('CA', 'AA', 'AE','AS','NH','OT/MR'), pool$Race2)
  pool$Hispan2 <- dict_transform(c(0,1), c('No', 'Yes'), pool$Hispan2)
  pool$SEX <- dict_transform(c(1,2),c('M','F'), pool$SEX)
  pool <- pool[order(pool$Race2,pool$Hispan2,pool$SEX),]
  
  pool <- group_code_gen(pool, grp_codes_df)
  
    cogs_data_diag <- cogs_data[cogs_data$cDiagnosis4 == Diag4,]
  cogs_counts <- plyr::count(cogs_data_diag, c('cRace2', 'cHispanicorLatino', 'cGender'))
  cogs_counts$props <- cogs_counts$freq / sum(cogs_counts$freq)
  cogs_counts <- group_code_gen(cogs_counts, grp_codes_df)
  cogs_counts

  # These are the unicorns - ignore these 
  pool[pool$group_code %in% setdiff(pool$group_code, cogs_counts$group_code),]
  # Asian Hispanics
  # American indians/Alaska natives
  # Native Hawaiian/ Pacific Islander Hispanics
  
  pool <- pool[pool$group_code %in% intersect(pool$group_code, cogs_counts$group_code),]
  
  
  return (pool) 
}
```

## Sampling Algorithm
```{r}
sampling_algorithm <- function(cogs_og, pool_df, scale_factor, thresh, n_iter, do_print = FALSE, suppress_df = TRUE) {
  # making a copy of the original cogs data
  # this copy will be updated in each pass
  cogs_counts_updated <- cogs_og[, c('group_code', 'freq', 'props')]
  cogs_counts_updated$freq_og <- cogs_og$freq
  cogs_counts_updated$props_og <- cogs_og$props
  cogs_counts_updated$props_target <- pool_df$prop
  cogs_counts_updated <- cogs_counts_updated[, c('group_code', 'freq', 'freq_og','props_og','props_target','props')]

  n_steps <- 0
  size_arg <- sum(cogs_og$freq) * scale_factor
  
  # start loop here
  
  
  number_rejected <- data.frame(group_code = cogs_og$group_code,
                                  n = rep(0, nrow(cogs_og)))          
  
  for (N in 1:n_iter) {
    
    # check stop condition: if all the new proportions are within 0.05 of the acs proportions, then stop
    if (all(cogs_counts_updated$props >= (pool_df$prop - thresh)&
    cogs_counts_updated$props <= pool_df$prop + thresh)) {
    # if (all(((cogs_counts_updated$props - pool_df$prop) / pool_df$prop) < thresh)) {
      if (do_print) {cat('Number of steps:', n_steps, '\n')}
      break
    }
  
    
    
    # Methodology: sample from the group_codes based on the proportion found in the original cogs_counts
    
    sam <- sample(x = cogs_og$group_code, size = size_arg, prob = cogs_og$props, replace = TRUE)
    sam_counts <- plyr::count(sam)
    
    # verifying that all the group codes are in the right order
    # all(cogs_og$group_code == pool_df$group_code)
    
    # number_rejected <- data.frame(group_code = cogs_og$group_code,
    #                               n = rep(0, nrow(cogs_og)))
    # for each group code in cogs_counts
    for (i in 1:nrow(cogs_counts_updated)) {
      
      # first check if the group was in the sample
      if (any(cogs_counts_updated$group[i] %in% sam_counts$x)) {
        # check whether the category is currently overrepresented
        # if it is, then don't touch it
        if (cogs_counts_updated$props[i] > pool_df$prop[i]) {
          # update the number rejected
          # but don't update the counts
        # if (((cogs_counts_updated$props[i] - pool_df$prop[i]) / pool_df$prop[i]) >= thresh) {
          number_rejected$n[number_rejected$group_code == cogs_counts_updated$group_code[i]] <- number_rejected$n[number_rejected$group_code == cogs_counts_updated$group_code[i]] + sam_counts$freq[sam_counts$x == cogs_counts_updated$group_code[i]]
          
        } else {
          # the add the people to the sample
          cogs_counts_updated$freq[i] <- cogs_counts_updated$freq[i] + sam_counts$freq[sam_counts$x == cogs_counts_updated$group_code[i]] 
        }
      }
    }
    
    # update the proportions
    cogs_counts_updated$props <- cogs_counts_updated$freq / sum(cogs_counts_updated$freq)
    
    # update the number of iterations
    n_steps <- n_steps + 1
  }
  
  if (N == n_iter && do_print) {
    cat('Did not converge in', n_steps, 'steps.\n')
  }
  
  if (suppress_df) {
    return(n_steps) 
  } else {
    return (list(cogs_counts_updated, number_rejected, n_steps))
  }
}
```
# Hypothesis testing for the pools

## CS
```{r}

# getting proportions for the categories from COGS2 data
prop_ct_cs <- plyr::count(df_COGS2[df_COGS2$cDiagnosis4 == 'CS',], c('cRace2', 'cHispanicorLatino', 'cGender'))
prop_ct_cs$props <- prop_ct_cs$freq / sum(prop_ct_cs$freq)
prop_ct_cs <- group_code_gen(prop_ct_cs, group_codes_df)

# Generating the CS pool
pool_cs <- pool_gen('CS', df_COGS2, df_acs, group_codes_df)

all(prop_ct_cs$group_code == pool_cs$group_code)

# Checking if some group codes are not present between the pool and COGS2
pool_cs[pool_cs$group_code %in% setdiff(pool_cs$group_code, prop_ct_cs$group_code),] # there are no missing codes

setdiff(prop_ct_cs$group_code, pool_cs$group_code) # there are no missing codes

df_comparison_cs <- cbind(prop_ct_cs, pool_cs$prop)
df_comparison_cs$group_code <- NULL
df_comparison_cs$sam_over <- ifelse(prop_ct_cs$props > pool_cs$prop, 'Over','-')
df_comparison_cs$sam_under <- ifelse(prop_ct_cs$props < pool_cs$prop, 'Under','-')

sig_res_p_vals_cs <- rep(0, nrow(df_comparison_cs))
for (i in 1:nrow(df_comparison_cs)) {
  test_obj <- binom.test(df_comparison_cs$freq[i], n = sum(prop_ct_cs$freq), p = df_comparison_cs$`pool_cs$prop`[i], alternative = 'two.sided')
  sig_res_p_vals_cs[i] <- test_obj$p.value
}

sig_res_p_vals_cs

# adjusting for multiple comparisons
holm_corr_cs <- p.adjust(sig_res_p_vals_cs, "holm")
holm_corr_cs

sig_desig_cs <- ifelse(holm_corr_cs < 0.05, '**', '-')
sig_desig_cs


df_comparison_cs$significance <- sig_desig_cs
df_comparison_cs$holm_pval <- holm_corr_cs
View(df_comparison_cs)

# changing the column names to be more recognizable
colnames(df_comparison_cs)
colnames(df_comparison_cs) <- c('Race', 'Hispanic/Latino', 'Gender', 'COGS2\nCount', 'COGS2\nProportion', 'ACS\n Proportion', 'Sam_over', 'Sam_under', 'Significance', 'Holm-corrected\np-value')

View(df_comparison_cs)

df_comparison_cs$`Sampling Trend` <- rep('-', nrow(df_comparison_cs))
df_comparison_cs$`Sampling Trend`[df_comparison_cs$Sam_over == 'Over'] <- 'Over'
df_comparison_cs$`Sampling Trend`[df_comparison_cs$Sam_under == 'Under'] <- 'Under'

colnames(df_comparison_cs)

df_comparison_cs <- df_comparison_cs[, c('Race', 'Hispanic/Latino', 'Gender', 'COGS2\nCount', 'COGS2\nProportion', 'ACS\n Proportion', 'Sampling Trend', 'Significance', 'Holm-corrected\np-value')]
View(df_comparison_cs)

# exporting the table
png('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\3 Studies Dataset\\Dataset Merge\\Rmd Files\\COGS2 Sim_abstract_093023\\CS_hyp_test.png', height = 50*nrow(df_comparison_cs), width = 200*ncol(df_comparison_cs))
grid.table(df_comparison_cs)
dev.off()
```

## SZ
```{r}

# getting proportions for the categories from COGS2 data
prop_ct_sz <- plyr::count(df_COGS2[df_COGS2$cDiagnosis4 == 'SZSAFD',], c('cRace2', 'cHispanicorLatino', 'cGender'))
prop_ct_sz$props <- prop_ct_sz$freq / sum(prop_ct_sz$freq)
prop_ct_sz <- group_code_gen(prop_ct_sz, group_codes_df)

# Generating the CS pool
pool_sz <- pool_gen('SZSAFD', df_COGS2, df_acs, group_codes_df)

all(prop_ct_sz$group_code == pool_sz$group_code)

# Checking if some group codes are not present between the pool and COGS2
pool_sz[pool_sz$group_code %in% setdiff(pool_sz$group_code, prop_ct_sz$group_code),] # there are no missing codes

setdiff(prop_ct_sz$group_code, pool_sz$group_code) # there are no missing codes

df_comparison_sz <- cbind(prop_ct_sz, pool_sz$prop)
df_comparison_sz$group_code <- NULL
df_comparison_sz$sam_over <- ifelse(prop_ct_sz$props > pool_sz$prop, 'Over','-')
df_comparison_sz$sam_under <- ifelse(prop_ct_sz$props < pool_sz$prop, 'Under','-')

sig_res_p_vals_sz <- rep(0, nrow(df_comparison_sz))
for (i in 1:nrow(df_comparison_sz)) {
  test_obj <- binom.test(df_comparison_sz$freq[i], n = sum(prop_ct_sz$freq), p = df_comparison_sz$`pool_sz$prop`[i], alternative = 'two.sided')
  sig_res_p_vals_sz[i] <- test_obj$p.value
}

sig_res_p_vals_sz

# adjusting for multiple comparisons
holm_corr_sz <- p.adjust(sig_res_p_vals_sz, "holm")
holm_corr_sz

sig_desig_sz <- ifelse(holm_corr_sz < 0.05, '**', '-')
sig_desig_sz


df_comparison_sz$significance <- sig_desig_sz
df_comparison_sz$holm_pval <- holm_corr_sz
View(df_comparison_sz)

# changing the column names to be more recognizable
colnames(df_comparison_sz)
colnames(df_comparison_sz) <- c('Race', 'Hispanic/Latino', 'Gender', 'COGS2\nCount', 'COGS2\nProportion', 'ACS\n Proportion', 'Sam_over', 'Sam_under', 'Significance', 'Holm-corrected\np-value')

View(df_comparison_sz)

df_comparison_sz$`Sampling Trend` <- rep('-', nrow(df_comparison_sz))
df_comparison_sz$`Sampling Trend`[df_comparison_sz$Sam_over == 'Over'] <- 'Over'
df_comparison_sz$`Sampling Trend`[df_comparison_sz$Sam_under == 'Under'] <- 'Under'

colnames(df_comparison_sz)

df_comparison_sz <- df_comparison_sz[, c('Race', 'Hispanic/Latino', 'Gender', 'COGS2\nCount', 'COGS2\nProportion', 'ACS\n Proportion', 'Sampling Trend', 'Significance', 'Holm-corrected\np-value')]
View(df_comparison_sz)

# exporting the table
png('C:\\Users\\danie\\Documents\\Joshi Lab Materials\\3 Studies Dataset\\Dataset Merge\\Rmd Files\\COGS2 Sim_abstract_093023\\SZ_hyp_test.png', height = 50*nrow(df_comparison_sz), width = 200*ncol(df_comparison_sz))
grid.table(df_comparison_sz)
dev.off()
```

# Running the Simulations

## CS
```{r}
## Finding the Distribution of number of steps for convergence at 0.025 level with resampling 50% of the original sample size
n_sim <- 1000
th <- 0.025
sf <- 0.5

# getting the original counts for cs
df_COGS2_cs <- df_COGS2[df_COGS2$cDiagnosis4 == 'CS',]
cogs_counts_cs <- plyr::count(df_COGS2_cs, c('cRace2', 'cHispanicorLatino', 'cGender'))
cogs_counts_cs$props <- cogs_counts_cs$freq / sum(cogs_counts_cs$freq)
cogs_counts_cs <- group_code_gen(cogs_counts_cs, group_codes_df)
cogs_counts_cs

# checking the algorithm
cs_check <- sampling_algorithm(cogs_og = cogs_counts_cs, pool_df = pool_cs, scale_factor = sf, thresh = th, n_iter = 1000, suppress_df = FALSE)

steps_storage_cs_acs <- rep(0, n_sim)
start_time <- Sys.time()
for (i in 1:n_sim) {
  steps_storage_cs_acs[i] <- sampling_algorithm(cogs_og = cogs_counts_cs, pool_df = pool_cs, scale_factor = sf, thresh = th, n_iter = 1000, suppress_df = TRUE)
}

end_time <- Sys.time()
end_time - start_time
# rng <- range(steps_storage_cs_acs)
# hist(steps_storage_cs_acs, main = 'CS: Number of Resamples\nuntil Convergence', breaks = rng[1]:rng[2], xlab = "Number of Resamples")
# hist(steps_storage_cs_acs, freq = TRUE, main = 'CS: Number of Resamples\nuntil Convergence', breaks = rng[1]:rng[2], xlab = 'Number of Resamples')
# title(sub = paste('Scale factor:', sf, '\tThreshold:', th), font.sub = 3, col.sub = 'darkgray')
# grid()
# steps_storage_cs_acs <- sort(steps_storage_cs_acs)
# conf_int <- c(steps_storage_cs_acs[0.025*n_sim], steps_storage_cs_acs[0.975*n_sim])
# med_step <- median(steps_storage_cs_acs)

# alternate representation
steps_cs_cts <- plyr::count(steps_storage_cs_acs)
#plot(density(steps_storage_cs_acs), lwd = 1.5, main = 'CS: Number of Resamples\nuntil Convergence', xlab = 'Number of Resamples')
plot(steps_cs_cts$x, steps_cs_cts$freq/sum(steps_cs_cts$freq), main = 'HCS: Number of Resamples\nuntil Convergence', type = 'h', xlab = 'Number of Resamples', ylab = 'Density', lty = 1)
title(sub = paste('Scale factor:', sf, '\tThreshold:', th), font.sub = 3, col.sub = 'darkgray')
points(x = steps_cs_cts$x, y = steps_cs_cts$freq/sum(steps_cs_cts$freq), pch = 15)
minor.tick(nx = 2, ny = 2,   # Ticks density
           tick.ratio = 0.5)
grid()

perc_names <- c("2.5th",
                "1st Quartile",
                "Median",
                "3rd Quartile",
                "97.5th"
                )
perc_res <- quantile(steps_storage_cs_acs, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))

sum_stats <- data.frame(Percentile = names(perc_res),
                        Value = round(unname(perc_res)))
sum_stats

tbl <- kbl(sum_stats, caption = "Number of Resamples until Convergence for Healthy Control Subjects", table.attr = "style='width:50%;'" ) %>%
kable_styling(bootstrap_options = "striped", full_width = T, position = "center")
tbl


mean(steps_storage_cs_acs)
sd(steps_storage_cs_acs)
```

## SZ
```{r}
## Finding the Distribution of number of steps for convergence at 0.03 level with resampling 50% of the original sample size

n_sim <- 1000
th <- 0.025
sf <- 0.50

# getting the original counts for cs
df_COGS2_sz <- df_COGS2[df_COGS2$cDiagnosis4 == 'SZSAFD',]
cogs_counts_sz <- plyr::count(df_COGS2_sz, c('cRace2', 'cHispanicorLatino', 'cGender'))
cogs_counts_sz$props <- cogs_counts_sz$freq / sum(cogs_counts_sz$freq)
cogs_counts_sz <- group_code_gen(cogs_counts_sz, group_codes_df)
cogs_counts_sz

steps_storage_sz_acs <- rep(0, n_sim)
start_time <- Sys.time()
for (i in 1:n_sim) {
  steps_storage_sz_acs[i] <- sampling_algorithm(cogs_og = cogs_counts_sz, pool_df = pool_sz, scale_factor = sf, thresh = th, n_iter = 1000, suppress_df = TRUE)
}

end_time <- Sys.time()
end_time - start_time
rng <- range(steps_storage_sz_acs)
# hist(steps_storage_sz_acs, main = 'CS: Number of Resamples\nuntil Convergence', breaks = rng[1]:rng[2], xlab = "Number of Resamples")
# hist(steps_storage_sz_acs, freq = TRUE, main = 'CS: Number of Resamples\nuntil Convergence', breaks = rng[1]:rng[2], xlab = 'Number of Resamples')
# title(sub = paste('Scale factor:', sf, '\tThreshold:', th), font.sub = 3, col.sub = 'darkgray')
# grid()
# steps_storage_sz_acs <- sort(steps_storage_sz_acs)
# conf_int <- c(steps_storage_sz_acs[0.025*n_sim], steps_storage_sz_acs[0.975*n_sim])
# med_step <- median(steps_storage_sz_acs)

# alternate representation
steps_sz_cts <- plyr::count(steps_storage_sz_acs)
#plot(density(steps_storage_sz_acs), lwd = 1.5, main = 'CS: Number of Resamples\nuntil Convergence', xlab = 'Number of Resamples')
plot(steps_sz_cts$x, steps_sz_cts$freq/sum(steps_sz_cts$freq), main = 'SZ: Number of Resamples\nuntil Convergence', type = 'h', xlab = 'Number of Resamples', ylab = 'Density', lty = 1)
title(sub = paste('Scale factor:', sf, '\tThreshold:', th), font.sub = 3, col.sub = 'darkgray')
points(x = steps_sz_cts$x, y = steps_sz_cts$freq/sum(steps_sz_cts$freq), pch = 15)
minor.tick(nx = 2, ny = 2,   # Ticks density
           tick.ratio = 0.5)
grid()

perc_names <- c("2.5th",
                "1st Quartile",
                "Median",
                "3rd Quartile",
                "97.5th"
                )
perc_res_sz <- quantile(steps_storage_sz_acs, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))

sum_stats_sz <- data.frame(Percentile = names(perc_res_sz),
                        Value = unname(perc_res_sz))
sum_stats_sz

tbl <- kbl(sum_stats_sz, caption = "Number of Resamples until Convergence for SZ Subjects", table.attr = "style='width:50%;'" ) %>%
kable_styling(bootstrap_options = "striped", full_width = T, position = "center")
tbl


steps_storage_sz_acs[0.25*1000]
steps_storage_sz_acs[0.75*1000]

mean(steps_storage_sz_acs)
sd(steps_storage_sz_acs)
```

## SZ to HCS

### Generating the HCS Pool 
```{r}
## New pooled target dataframe
pool_cs <- plyr::count(df_COGS2[df_COGS2$cDiagnosis4 == 'CS', ], c('cRace2', 'cHispanicorLatino', 'cGender'))
pool_cs$prop <- pool_cs$freq / sum(pool_cs$freq)
pool_cs

pool_cs <- group_code_gen(pool_cs, group_codes_df)
pool_cs
```

### Updating the cs pool to exclude unicorns
```{r}
pool_cs <- pool_cs[pool_cs$group_code %in% intersect(pool_cs$group_code, cogs_counts_sz$group_code),]
nrow(pool_cs)

# adding the missing group codes
setdiff(pool_cs$group_code, cogs_counts_sz$group_code) # everyone in CS is contained in SZ

# NOTE: there are some individuals that are in SZ that are not in CS
miss_codes <- setdiff(cogs_counts_sz$group_code, pool_cs$group_code)
df_miss <- data.frame(group_code = miss_codes,
                      prop = rep(0, length(miss_codes)))
pool_cs_complete <- rbind(pool_cs[, c('group_code', 'prop')], df_miss)
pool_cs_complete <- pool_cs_complete[order(pool_cs_complete$group_code),]
rownames(pool_cs_complete) <- NULL
pool_cs_complete

# checking that the rows match up
all(pool_cs_complete$group_code == cogs_counts_sz$group_code)
```

### Testing the new sampling function
```{r}
nrow(pool_cs_complete)
nrow(cogs_counts_sz)
s3 <- Sys.time()
out <- sampling_algorithm(cogs_counts_sz, pool_cs_complete, scale_factor = 0.5, thresh = 0.025, 1000, suppress_df= TRUE)

s4 <- Sys.time()

s4 - s3 

out2 <- sampling_algorithm(cogs_counts_sz, pool_cs_complete, scale_factor = 0.5, thresh = 0.025, 1000, suppress_df= FALSE)

```

### Running the simulation
```{r}
n_sim <- 1000
sf <- 0.5
th <- 0.025

steps_storage <- rep(0, n_sim)
start_time <- Sys.time()
for (i in 1:n_sim) {
  steps_storage[i] <- sampling_algorithm(cogs_counts_sz, pool_cs_complete, scale_factor = sf, thresh = th, 1000, suppress_df= TRUE)
}

end_time <- Sys.time()
end_time - start_time
rng <- range(steps_storage)
hist(steps_storage, main = 'SZSAFD to HCS: Number of Resamples\nuntil Convergence', xlab = "Number of Resamples")
hist(steps_storage, freq = TRUE, xlim = c(0, max(steps_storage)), breaks = 0:rng[2], xlab = 'Number of Resamples', main = 'SZSAFD to HCS: Resamples\nuntil Convergence')
title(sub = paste('Scale factor:', sf, '\tThreshold:', th), font.sub = 3, col.sub = 'darkgray')
grid()

steps_sz_cs <- plyr::count(steps_storage)

# Scatterplot representation
plot(steps_sz_cs$x, steps_sz_cs$freq/sum(steps_sz_cs$freq), main = 'SZ: Number of Resamples\nuntil Convergence', type = 'h', xlab = 'Number of Resamples', ylab = 'Density', lty = 1)
title(sub = paste('Scale factor:', sf, '\tThreshold:', th), font.sub = 3, col.sub = 'darkgray')
points(x = steps_sz_cs$x, y = steps_sz_cs$freq/sum(steps_sz_cs$freq), pch = 15)
minor.tick(nx = 2, ny = 2,   # Ticks density
           tick.ratio = 0.5)
grid()


library(kableExtra)
library(tableHTML)

perc_res_sz_cs <- quantile(steps_storage, probs = c(0.025, 0.25, 0.5, 0.75, 0.975))

sum_stats_sz_cs <- data.frame(Percentile = names(perc_res_sz_cs),
                        Value = unname(perc_res_sz_cs))
sum_stats

tbl <- kbl(sum_stats_sz_cs, caption = "Number of Resamples until SZSAFD Convergence to Control Subjects", table.attr = "style='width:50%;'" ) %>%
kable_styling(bootstrap_options = "striped", full_width = T, position = "center")
tbl

mean(steps_storage)
sd(steps_storage)

```

# Generating the background information for COGS2
```{r}
# counting the controls and the SZ

plyr::count(df_COGS2, 'cDiagnosis4') # 1062 CS; 1415 SZSAFD
```